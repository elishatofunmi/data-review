{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# introduction to machine learning by muller\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = make_blobs(random_state = 0)\n",
    "\n",
    "x_train, x_test, y_train,y_test = train_test_split(x,y, random_state = 0)\n",
    "\n",
    "logreg = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "logreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let's evalueate logisticregression on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_validation scores:  [ 0.96078431  0.92156863  0.95833333]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logreg, iris.data, iris.target)\n",
    "print ('cross_validation scores: ', scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "by default cross-val-score performed 3 fold cross-validation, returning 3 accuracy values. we can change the number of folds by changing the cv parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.96666667,  0.93333333,  0.9       ,  1.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(logreg, iris.data,iris.target, cv = 5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96000000000000019"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benefits of cross_validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for regression , scikit-learn uses the standard k-fold cross-validation by default. scikit-learn does not use k-fold for classificaton but rather stratified k-fold-cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.93333333,  0.43333333,  0.96666667,  0.43333333])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits = 5)\n",
    "\n",
    "cross_val_score(logreg, iris.data, iris.target, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.93333333,  0.43333333,  0.96666667,  0.43333333])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfolds = KFold(n_splits = 3)\n",
    "cross_val_score(logreg, iris.data, iris.target, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9 ,  0.96,  0.96])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling the dataset by setting shuffle parameter to true and the random_state value\n",
    "kfold = KFold(n_splits = 3, shuffle = True, random_state = 0)\n",
    "cross_val_score(logreg, iris.data, iris.target, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cv iteratons:  150\n",
      "mean accuracy:  0.953333333333\n"
     ]
    }
   ],
   "source": [
    "# leave-one-out-cross-validation\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv = loo)\n",
    "print (\"Number of cv iteratons: \", len(scores))\n",
    "print (\"mean accuracy: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92      ,  0.84      ,  0.92      ,  0.96      ,  0.96      ,\n",
       "        0.93333333,  0.98666667,  0.93333333,  0.97333333,  0.92      ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle-split-cross-validation\n",
    "\n",
    "# the following code splits the dataset into 50% training set and 50% test set\n",
    "# for 10 iterations\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffle_split = ShuffleSplit(test_size = .5, train_size =.5, n_splits = 10)\n",
    "cross_val_score(logreg, iris.data, iris.target, cv = shuffle_split)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There is also a stratified variant of ShuffleSplit, aptly named StratifiedShuffleSplit, which can provide more reliable results for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LabelKFold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-bcede2228ab2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# label_kfold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# create synthetic dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LabelKFold'"
     ]
    }
   ],
   "source": [
    "# label_kfold\n",
    "\n",
    "from sklearn.model_selection import LabelKFold\n",
    "# create synthetic dataset\n",
    "\n",
    "x, y = make_blobs(n_samples = 12, random_state = 0)\n",
    "# assume the first 3 samples belong to the same group, then the next 4 etc.\n",
    "\n",
    "labels = [0,0,0,1,1,1,1,2,2,3,3,3]\n",
    "cross_val_score(logreg, x, y, labels, cv = LabelKFold(n_folds = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn' has no attribute 'm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-4128bebdc1fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__all__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__all__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LabelKFold'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn' has no attribute 'm'"
     ]
    }
   ],
   "source": [
    "for k in sklearn.__all__:\n",
    "    m = k.strip('')\n",
    "    for j in sklearn.m.__all__:\n",
    "        l = j.strip('')\n",
    "        if j == 'LabelKFold':\n",
    "            print ('found', m, l)\n",
    "        else:\n",
    "            print ('not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 112 size of test set: 38\n",
      "Best train score:  1.0\n",
      "best test_score:  0.973684210526\n",
      "Best parameter:  {'C': 100, 'gamma': 1}\n",
      "test score at paramter value is:  0.973684210526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state =0)\n",
    "print (\"Size of training set: %d size of test set: %d\" % (x_train.shape[0], x_test.shape[0]))\n",
    "\n",
    "best_test_score = []\n",
    "best_score = 0\n",
    "for gamma in [0.001, 0.01,0.1,1,10,100]:\n",
    "    for C in [0.001, 0.01,0.1,10,100]:\n",
    "        # for each combination of paramters\n",
    "        # train as SVC\n",
    "        svm = SVC(gamma = gamma, C = C)\n",
    "        svm.fit(x_train, y_train)\n",
    "        score = svm.score(x_train, y_train)\n",
    "        y_predict = svm.predict(x_test)\n",
    "       # score1 = svm.score(y_test, y_predict)\n",
    "        #print (score1)\n",
    "        score1 = sum(y_predict == y_test)/len(y_predict)\n",
    "        best_test_score.append(score1)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C':C, 'gamma':gamma}\n",
    "            test_score_at_param = score1\n",
    "            \n",
    "print (\"Best train score: \", best_score)\n",
    "print (\"best test_score: \", max(best_test_score))\n",
    "print (\"Best parameter: \", best_parameters)\n",
    "print (\"test score at paramter value is: \", test_score_at_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The danger of overfitting the parameters and the validatio set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 112 size of test set: 38\n",
      "Best train score:  1.0\n",
      "best test_score:  0.973684210526\n",
      "Best parameter:  {'C': 100, 'gamma': 1}\n",
      "test score at paramter value is:  0.973684210526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state =0)\n",
    "print (\"Size of training set: %d size of test set: %d\" % (x_train.shape[0], x_test.shape[0]))\n",
    "\n",
    "best_test_score = []\n",
    "best_score = 0\n",
    "for gamma in [0.001, 0.01,0.1,1,10,100]:\n",
    "    for C in [0.001, 0.01,0.1,1,10,100]:\n",
    "        # for each combination of paramters\n",
    "        # train as SVC\n",
    "        svm = SVC(gamma = gamma, C = C)\n",
    "        svm.fit(x_train, y_train)\n",
    "        score = svm.score(x_train, y_train)\n",
    "        y_predict = svm.predict(x_test)\n",
    "       # score1 = svm.score(y_test, y_predict)\n",
    "        #print (score1)\n",
    "        score1 = sum(y_predict == y_test)/len(y_predict)\n",
    "        best_test_score.append(score1)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C':C, 'gamma':gamma}\n",
    "            test_score_at_param = score1\n",
    "            \n",
    "print (\"Best train score: \", best_score)\n",
    "print (\"best test_score: \", max(best_test_score))\n",
    "print (\"Best parameter: \", best_parameters)\n",
    "print (\"test score at paramter value is: \", test_score_at_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: 84 size of validation set: 28 size of test set: 38 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# split data into train+ validation set and test set\n",
    "x_trainval, x_test, y_trainval, y_test = train_test_split(iris.data, iris.target, random_state = 0)\n",
    "# split trin+ validation set into train and validation set\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_trainval, y_trainval, random_state =1)\n",
    "\n",
    "print (\"size of training set: %d size of validation set: %d size of test set: %d \"% (x_train.shape[0], x_valid.shape[0], x_test.shape[0]))\n",
    "best_score  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for gamma in [0.001, 0.01,0.1,1,10,100]:\n",
    "    for C in [0.001, 0.01,0.1,1,10,100]:\n",
    "        # for each combination of paramters\n",
    "        # train as SVC\n",
    "        svm = SVC(gamma = gamma, C = C)\n",
    "        svm.fit(x_train, y_train)\n",
    "        # evaluate the SVC on the test set\n",
    "        score = svm.score(x_valid, y_valid)\n",
    "        # if we got a better score, store the score and paramters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_paramers = {'C':C, 'gamma':gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set:  0.964285714286\n",
      "Best parameters:  {'C': 100, 'gamma': 1}\n",
      "test set score with best paramters:  0.973684210526\n"
     ]
    }
   ],
   "source": [
    "# rebuild a model on the combined traing and validation set, and evaluate it on the test\n",
    "# set\n",
    "svm = SVC(** best_parameters)\n",
    "svm.fit(x_trainval, y_trainval)\n",
    "test_score = svm.score(x_test, y_test)\n",
    "print (\"Best score on validation set: \", best_score)\n",
    "print (\"Best parameters: \", best_parameters)\n",
    "print (\"test set score with best paramters: \",test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid-search with cross-validation\n",
    "\n",
    "best_score = 0\n",
    "for gamma in [0.001, 0.01,0.1,1,10,100]:\n",
    "    for C in [0.001, 0.01,0.1,1,10,100]:\n",
    "        # for each combination of paramters\n",
    "        # train as SVC\n",
    "        svm = SVC(gamma = gamma, C = C)\n",
    "        # perform cross-validation\n",
    "        scores = cross_val_score(svm, x_trainval, y_trainval, cv = 5)\n",
    "        # compute mean cross_validation accuracy\n",
    "        score = np.mean(scores)\n",
    "        # if we got a better score, store the score and paramters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_paramters = {\"C\":C, \"gamma\":gamma}\n",
    "        \n",
    "# rebuild a model on the combined training and validation set\n",
    "svm = SVC(**best_paramters)\n",
    "svm.fit(x_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'gamma' :[0.001, 0.01,0.1,1,10,100], 'C' : [0.001, 0.01,0.1,1,10,100]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "grid_search = GridSearchCV(SVC(), param_grid , cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state =0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The grid_search object that we created behaves just like a classifier, we can call the standard methods fit, predict, and score on it. \n",
    "A scikit-learn estimator that is created using another estimator is called a meta-estimator in scikit-learn. GridSearchCV is the most commonly used meta-estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cv', 'error_score', 'estimator__C', 'estimator__cache_size', 'estimator__class_weight', 'estimator__coef0', 'estimator__decision_function_shape', 'estimator__degree', 'estimator__gamma', 'estimator__kernel', 'estimator__max_iter', 'estimator__probability', 'estimator__random_state', 'estimator__shrinking', 'estimator__tol', 'estimator__verbose', 'estimator', 'fit_params', 'iid', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2 *n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train, y_train)\n",
    "GridSearchCV(cv = 5, error_score = 'raise', estimator = SVC(C = 1.0, cache_size = 200, \n",
    "                                                           class_weight = None, coef0 = 0.0,\n",
    "                                                           decision_function_shape = None,\n",
    "                                                           degree = 3, gamma = 'auto', kernel = 'rbf',\n",
    "                                                           max_iter = -1, probability = False, random_state = None, \n",
    "                                                           shrinking = True, tol = 0.001, verbose = False), \n",
    "            fit_params = {}, iid = True, n_jobs = 1, param_grid = {'C': [0.001,0.01,0.1,1,10,100],\n",
    "                                                                  'gamma': [0.001,0.01,0.1,1,10,100]},\n",
    "            pre_dispatch = '2 *n_jobs', refit = True, scoring = None, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.01}\n",
      "0.973214285714\n"
     ]
    }
   ],
   "source": [
    "print (grid_search.best_params_)\n",
    "print (grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the result of cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.36607, std: 0.01137, params: {'C': 0.001, 'gamma': 0.001},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.001, 'gamma': 0.01},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.001, 'gamma': 0.1},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.001, 'gamma': 1},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.001, 'gamma': 10},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.001, 'gamma': 100},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.01, 'gamma': 0.001},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.01, 'gamma': 0.01},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.01, 'gamma': 0.1},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.01, 'gamma': 1},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.01, 'gamma': 10},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.01, 'gamma': 100},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.1, 'gamma': 0.001},\n",
       " mean: 0.69643, std: 0.01333, params: {'C': 0.1, 'gamma': 0.01},\n",
       " mean: 0.91964, std: 0.04442, params: {'C': 0.1, 'gamma': 0.1},\n",
       " mean: 0.95536, std: 0.03981, params: {'C': 0.1, 'gamma': 1},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.1, 'gamma': 10},\n",
       " mean: 0.36607, std: 0.01137, params: {'C': 0.1, 'gamma': 100},\n",
       " mean: 0.69643, std: 0.01333, params: {'C': 1, 'gamma': 0.001},\n",
       " mean: 0.92857, std: 0.04278, params: {'C': 1, 'gamma': 0.01},\n",
       " mean: 0.96429, std: 0.03405, params: {'C': 1, 'gamma': 0.1},\n",
       " mean: 0.94643, std: 0.03251, params: {'C': 1, 'gamma': 1},\n",
       " mean: 0.91964, std: 0.06507, params: {'C': 1, 'gamma': 10},\n",
       " mean: 0.50893, std: 0.04666, params: {'C': 1, 'gamma': 100},\n",
       " mean: 0.92857, std: 0.04278, params: {'C': 10, 'gamma': 0.001},\n",
       " mean: 0.96429, std: 0.03405, params: {'C': 10, 'gamma': 0.01},\n",
       " mean: 0.96429, std: 0.01793, params: {'C': 10, 'gamma': 0.1},\n",
       " mean: 0.93750, std: 0.04556, params: {'C': 10, 'gamma': 1},\n",
       " mean: 0.91964, std: 0.06507, params: {'C': 10, 'gamma': 10},\n",
       " mean: 0.56250, std: 0.04966, params: {'C': 10, 'gamma': 100},\n",
       " mean: 0.96429, std: 0.03405, params: {'C': 100, 'gamma': 0.001},\n",
       " mean: 0.97321, std: 0.02234, params: {'C': 100, 'gamma': 0.01},\n",
       " mean: 0.95536, std: 0.04983, params: {'C': 100, 'gamma': 0.1},\n",
       " mean: 0.94643, std: 0.05199, params: {'C': 100, 'gamma': 1},\n",
       " mean: 0.91964, std: 0.06507, params: {'C': 100, 'gamma': 10},\n",
       " mean: 0.56250, std: 0.04966, params: {'C': 100, 'gamma': 100}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This attribute above contains the mean cross-validation accuracy (and it's standard deviation) for all paramter settings that we tried. As we were searching a two-dimensional grid of parameters (\"C\" and 'gamma'), this is best visualized as a head map. First, we extract the mean validation scores, then we reshape the scores so that the axes correspond to C and gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = [score.mean_validation_score for score in grid_search.grid_scores_]\n",
    "scores = np.array(scores).reshape(6,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using different cross-validation strategies with grid search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "similarly to cross_val_score, GridSearchCV uses stratified k-fold cross-validation by default for classification, and k-fold cross-validation for regression. However, you can also pass any cross-validation splitter, as the cv paramter in GridSearchCV.\n",
    "\n",
    "In particular, to get only a single split into a training and validation set, you can use ShuffleSplit or StratifedShuffleSplit with n_iter = 1. This might be helpful for very large datasets, or very slow models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested cross-validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "implementing nested cross_validation in scikit_learn is straightforward we call cross_val_score with an instance of GridSearchCV as the model\n",
    "\n",
    "Teh result of this procedure is a list of scores, not a model, and not a parameter setting. The score tell us how well a model generalizes, given the best parameters found by grid-search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [[ 0.36607143  0.36607143  0.36607143  0.36607143  0.36607143  0.36607143]\n",
      " [ 0.36607143  0.36607143  0.36607143  0.36607143  0.36607143  0.36607143]\n",
      " [ 0.36607143  0.69642857  0.91964286  0.95535714  0.36607143  0.36607143]\n",
      " [ 0.69642857  0.92857143  0.96428571  0.94642857  0.91964286  0.50892857]\n",
      " [ 0.92857143  0.96428571  0.96428571  0.9375      0.91964286  0.5625    ]\n",
      " [ 0.96428571  0.97321429  0.95535714  0.94642857  0.91964286  0.5625    ]]\n",
      "mean cross_validation score:  0.65625\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(GridSearchCV(SVC(), param_grid, cv = 5), iris.data, iris.target, cv = 5)\n",
    "print (\"Cross-validation scores: \", scores)\n",
    "print (\"mean cross_validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The result of our nested cross-validation can be summarized as SVC can also achieve 66% mean cross-validation accuracy on the iris dataset- nothing more and\n",
    "nothis less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nested_cv(x, y , inner_cv, outer_cv, Classifier, parameter_grid):\n",
    "    outer_scores = []\n",
    "    # for each split of the data in the outer cross-validation\n",
    "    # (split method return indices)\n",
    "    for training_samples, test_samples in outer_cv.split(x,y):\n",
    "        # find best parameter using inner cross-validation;\n",
    "        best_param = []\n",
    "        best_score = -np.inf\n",
    "        # interate over parameters\n",
    "        for parameters in parameter_grid:\n",
    "            # accumnulate score over inner splits\n",
    "            cv_scores = []\n",
    "            # interate over inner cross_validation\n",
    "            for inner_train, inner_test in inner_cv.split(x[training_samples], y[training_samples]):\n",
    "                # build classifier given paramters and training data\n",
    "                clf = Classifier(**parameters)\n",
    "                clf.fit(x[inner_train],y[inner_train])\n",
    "                # evaluate on inner test set\n",
    "                score = clf.score(x[inner_test], y[inner_test])\n",
    "                cv_scores.append(score)\n",
    "            # compute mean score over inner folds\n",
    "            mean_score = np.mean(cv_scores)\n",
    "            if mean_score > best_score:\n",
    "                # if better than so far, remember parameters\n",
    "                best_score = mean_score\n",
    "                best_params = parameters\n",
    "        #build classifier on best paramters using outer training set\n",
    "        clf= Classifier(**best_params)\n",
    "        clf.fit(x[training_samples], y[training_samples])\n",
    "        # evaluate\n",
    "        outer_scores.append(clf.score(x[test_samples], y[test_samples]))\n",
    "    return outer_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96666666666666667, 1.0, 0.96666666666666667, 0.96666666666666667, 1.0]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid, StratifiedKFold\n",
    "nested_cv(iris.data, iris.target, StratifiedKFold(5), StratifiedKFold(5), SVC, ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing cross-validation and grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "y = digits.target == 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, y, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted labels: [False]\n",
      "Score: 0.895556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(x_train, y_train)\n",
    "pred_most_frequent = dummy_majority.predict(x_test)\n",
    "print (\"predicted labels: %s\" % np.unique(pred_most_frequent))\n",
    "print (\"Score: %f\" % dummy_majority.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9177777777777778"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth = 2).fit(x_train, y_train)\n",
    "pred_tree = tree.predict(x_test)\n",
    "tree.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['constant', 'random_state', 'strategy'])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_majority.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy score: 0.800000\n",
      "logreg score: 0.977778\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier().fit(x_train, y_train)\n",
    "pred_dummy = dummy.predict(x_test)\n",
    "print ('dummy score: %f' %dummy.score(x_test, y_test))\n",
    "\n",
    "logreg = LogisticRegression(C = 0.1).fit(x_train,y_train)\n",
    "pred_logreg = logreg.predict(x_test)\n",
    "print ('logreg score: %f'% logreg.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clearly accuracy is an inadequate measure to quantify predictive performance in this imbalance setting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrices"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "one of the most comprehensive ways of representing the result of evaluating binary classification is using confusion matrices. Let's inspect the predictions \n",
    "of LogisticRegression above using the confusion_matrix function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[401   2]\n",
      " [  8  39]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "print (confusion)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This means of the 403 data points (sum of the first row) that are not a 4, 401 got predicted correctly as such, and two of which were incorrectly predicted as a four. Similarly there are 47 data points that are 4's, 39 of which got correcly classified, and 8 of which were predicted incorrectly as not a 4.\n",
    "\n",
    "Entries of the main diagonal of the confusion matrix correspond to correct classificatons, while other entries tell us how many samples of one class got mistakenly classified an another class.\n",
    "\n",
    "To complete the picture, we call correctly classified samples belonging to the positive class true positive and correctly classified samples of the negative class true negatives. These terms are usually abbreviated FP, FN, TP, TN and lead to the following interpretation for the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent class: \n",
      "[[403   0]\n",
      " [ 47   0]]\n",
      "\n",
      "Dummy model:\n",
      "[[354  49]\n",
      " [ 42   5]]\n",
      "\n",
      "Decision tree: \n",
      "[[390  13]\n",
      " [ 24  23]]\n",
      "\n",
      "Logistic Regression\n",
      "[[401   2]\n",
      " [  8  39]]\n"
     ]
    }
   ],
   "source": [
    "print (\"most frequent class: \")\n",
    "print (confusion_matrix(y_test, pred_most_frequent))\n",
    "print (\"\\nDummy model:\")\n",
    "print (confusion_matrix(y_test, pred_dummy))\n",
    "print (\"\\nDecision tree: \")\n",
    "print (confusion_matrix(y_test, pred_tree))\n",
    "print (\"\\nLogistic Regression\")\n",
    "print (confusion_matrix(y_test, pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(confusion_matrix, index = ['true\" not 4\"', 'true \"4\"'], \n",
    "                  columns =['predicted \"not 4\"', 'predicted \"4\"'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-e9d827ebbf31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mannot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, ax, xticklabels, yticklabels, mask, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0;32m    484\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                           yticklabels, mask)\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;31m# Add the pcolormesh kwargs here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;31m# Determine good default values for the colormapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         self._determine_cmap_params(plot_data, vmin, vmax,\n\u001b[1;32m--> 167\u001b[1;33m                                     cmap, center, robust)\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;31m# Sort out the annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m_determine_cmap_params\u001b[1;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[0;32m    202\u001b[0m                                cmap, center, robust):\n\u001b[0;32m    203\u001b[0m         \u001b[1;34m\"\"\"Use some heuristics to set good defaults for colorbar and range.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mcalc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvmin\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mvmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrobust\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcalc_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize = (2,2))\n",
    "sns.heatmap(df,annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function heatmap in module seaborn.matrix:\n",
      "\n",
      "heatmap(data, vmin=None, vmax=None, cmap=None, center=None, robust=False, annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white', cbar=True, cbar_kws=None, cbar_ax=None, square=False, ax=None, xticklabels=True, yticklabels=True, mask=None, **kwargs)\n",
      "    Plot rectangular data as a color-encoded matrix.\n",
      "    \n",
      "    This function tries to infer a good colormap to use from the data, but\n",
      "    this is not guaranteed to work, so take care to make sure the kind of\n",
      "    colormap (sequential or diverging) and its limits are appropriate.\n",
      "    \n",
      "    This is an Axes-level function and will draw the heatmap into the\n",
      "    currently-active Axes if none is provided to the ``ax`` argument.  Part of\n",
      "    this Axes space will be taken and used to plot a colormap, unless ``cbar``\n",
      "    is False or a separate Axes is provided to ``cbar_ax``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : rectangular dataset\n",
      "        2D dataset that can be coerced into an ndarray. If a Pandas DataFrame\n",
      "        is provided, the index/column information will be used to label the\n",
      "        columns and rows.\n",
      "    vmin, vmax : floats, optional\n",
      "        Values to anchor the colormap, otherwise they are inferred from the\n",
      "        data and other keyword arguments. When a diverging dataset is inferred,\n",
      "        one of these values may be ignored.\n",
      "    cmap : matplotlib colormap name or object, optional\n",
      "        The mapping from data values to color space. If not provided, this\n",
      "        will be either a cubehelix map (if the function infers a sequential\n",
      "        dataset) or ``RdBu_r`` (if the function infers a diverging dataset).\n",
      "    center : float, optional\n",
      "        The value at which to center the colormap. Passing this value implies\n",
      "        use of a diverging colormap.\n",
      "    robust : bool, optional\n",
      "        If True and ``vmin`` or ``vmax`` are absent, the colormap range is\n",
      "        computed with robust quantiles instead of the extreme values.\n",
      "    annot : bool or rectangular dataset, optional\n",
      "        If True, write the data value in each cell. If an array-like with the\n",
      "        same shape as ``data``, then use this to annotate the heatmap instead\n",
      "        of the raw data.\n",
      "    fmt : string, optional\n",
      "        String formatting code to use when adding annotations.\n",
      "    annot_kws : dict of key, value mappings, optional\n",
      "        Keyword arguments for ``ax.text`` when ``annot`` is True.\n",
      "    linewidths : float, optional\n",
      "        Width of the lines that will divide each cell.\n",
      "    linecolor : color, optional\n",
      "        Color of the lines that will divide each cell.\n",
      "    cbar : boolean, optional\n",
      "        Whether to draw a colorbar.\n",
      "    cbar_kws : dict of key, value mappings, optional\n",
      "        Keyword arguments for `fig.colorbar`.\n",
      "    cbar_ax : matplotlib Axes, optional\n",
      "        Axes in which to draw the colorbar, otherwise take space from the\n",
      "        main Axes.\n",
      "    square : boolean, optional\n",
      "        If True, set the Axes aspect to \"equal\" so each cell will be\n",
      "        square-shaped.\n",
      "    ax : matplotlib Axes, optional\n",
      "        Axes in which to draw the plot, otherwise use the currently-active\n",
      "        Axes.\n",
      "    xticklabels : list-like, int, or bool, optional\n",
      "        If True, plot the column names of the dataframe. If False, don't plot\n",
      "        the column names. If list-like, plot these alternate labels as the\n",
      "        xticklabels. If an integer, use the column names but plot only every\n",
      "        n label.\n",
      "    yticklabels : list-like, int, or bool, optional\n",
      "        If True, plot the row names of the dataframe. If False, don't plot\n",
      "        the row names. If list-like, plot these alternate labels as the\n",
      "        yticklabels. If an integer, use the index names but plot only every\n",
      "        n label.\n",
      "    mask : boolean array or DataFrame, optional\n",
      "        If passed, data will not be shown in cells where ``mask`` is True.\n",
      "        Cells with missing values are automatically masked.\n",
      "    kwargs : other keyword arguments\n",
      "        All other keyword arguments are passed to ``ax.pcolormesh``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ax : matplotlib Axes\n",
      "        Axes object with the heatmap.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Plot a heatmap for a numpy array:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> import numpy as np; np.random.seed(0)\n",
      "        >>> import seaborn as sns; sns.set()\n",
      "        >>> uniform_data = np.random.rand(10, 12)\n",
      "        >>> ax = sns.heatmap(uniform_data)\n",
      "    \n",
      "    Change the limits of the colormap:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(uniform_data, vmin=0, vmax=1)\n",
      "    \n",
      "    Plot a heatmap for data centered on 0:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> normal_data = np.random.randn(10, 12)\n",
      "        >>> ax = sns.heatmap(normal_data)\n",
      "    \n",
      "    Plot a dataframe with meaningful row and column labels:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> flights = sns.load_dataset(\"flights\")\n",
      "        >>> flights = flights.pivot(\"month\", \"year\", \"passengers\")\n",
      "        >>> ax = sns.heatmap(flights)\n",
      "    \n",
      "    Annotate each cell with the numeric value using integer formatting:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(flights, annot=True, fmt=\"d\")\n",
      "    \n",
      "    Add lines between each cell:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(flights, linewidths=.5)\n",
      "    \n",
      "    Use a different colormap:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(flights, cmap=\"YlGnBu\")\n",
      "    \n",
      "    Center the colormap at a specific value:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(flights, center=flights.loc[\"January\", 1955])\n",
      "    \n",
      "    Plot every other column label and don't plot row labels:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> data = np.random.randn(50, 20)\n",
      "        >>> ax = sns.heatmap(data, xticklabels=2, yticklabels=False)\n",
      "    \n",
      "    Don't draw a colorbar:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.heatmap(flights, cbar=False)\n",
      "    \n",
      "    Use different axes for the colorbar:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> grid_kws = {\"height_ratios\": (.9, .05), \"hspace\": .3}\n",
      "        >>> f, (ax, cbar_ax) = plt.subplots(2, gridspec_kw=grid_kws)\n",
      "        >>> ax = sns.heatmap(flights, ax=ax,\n",
      "        ...                  cbar_ax=cbar_ax,\n",
      "        ...                  cbar_kws={\"orientation\": \"horizontal\"})\n",
      "    \n",
      "    Use a mask to plot only part of a matrix\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> corr = np.corrcoef(np.random.randn(10, 200))\n",
      "        >>> mask = np.zeros_like(corr)\n",
      "        >>> mask[np.triu_indices_from(mask)] = True\n",
      "        >>> with sns.axes_style(\"white\"):\n",
      "        ...     ax = sns.heatmap(corr, mask=mask, vmax=.3, square=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help (sns.heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package seaborn:\n",
      "\n",
      "NAME\n",
      "    seaborn - # Capture the original matplotlib rcParams\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    algorithms\n",
      "    apionly\n",
      "    axisgrid\n",
      "    categorical\n",
      "    crayons\n",
      "    distributions\n",
      "    external (package)\n",
      "    linearmodels\n",
      "    matrix\n",
      "    miscplot\n",
      "    palettes\n",
      "    rcmod\n",
      "    tests (package)\n",
      "    timeseries\n",
      "    utils\n",
      "    widgets\n",
      "    xkcd_rgb\n",
      "\n",
      "DATA\n",
      "    crayons = {'Almond': '#EFDECD', 'Antique Brass': '#CD9575', 'Apricot':...\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    xkcd_rgb = {'acid green': '#8ffe09', 'adobe': '#bd6c48', 'algae': '#54...\n",
      "\n",
      "VERSION\n",
      "    0.7.1\n",
      "\n",
      "FILE\n",
      "    c:\\users\\acer\\anaconda3\\lib\\site-packages\\seaborn\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help (sns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score most frequent: 0.00\n",
      "f1 score dummy: 0.10\n",
      "f1 score tree: 0.55\n",
      "f1 score logreg: 0.89\n"
     ]
    }
   ],
   "source": [
    "# precison and recall, accuracy on the binary classificaton datasets.\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print (\"f1 score most frequent: %.2f\" %f1_score(y_test, pred_most_frequent))\n",
    "print (\"f1 score dummy: %.2f\" %f1_score(y_test, pred_dummy))\n",
    "print (\"f1 score tree: %.2f\" % f1_score(y_test, pred_tree))\n",
    "print (\"f1 score logreg: %.2f\" % f1_score(y_test, pred_logreg))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if we want a more comprehensive summary of precison, recall and f1 score, we can use the classification_report conveinience function to compute all three at once and print them in a nice format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   not nine       0.90      1.00      0.94       403\n",
      "       nine       0.00      0.00      0.00        47\n",
      "\n",
      "avg / total       0.80      0.90      0.85       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test,pred_most_frequent, target_names = ['not nine', 'nine']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   not nine       0.89      0.88      0.89       403\n",
      "       nine       0.09      0.11      0.10        47\n",
      "\n",
      "avg / total       0.81      0.80      0.80       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test,pred_dummy, target_names = ['not nine', 'nine']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   not nine       0.98      1.00      0.99       403\n",
      "       nine       0.95      0.83      0.89        47\n",
      "\n",
      "avg / total       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test,pred_logreg, target_names = ['not nine', 'nine']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-e501a08f7b45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m7.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_decision_threshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    524\u001b[0m             raise ValueError(\n\u001b[0;32m    525\u001b[0m                 \u001b[1;34m\"The number of classes has to be greater than one; got %d\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m                 % len(cls))\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "x, y = make_blobs(n_samples = 400, centers = (2,0), cluster_std = [7.0,2], random_state = 22)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state = 0)\n",
    "svc = SVC(gamma = .05).fit(x_train, y_train)\n",
    "sklearn.plots.plot_decision_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mglearn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Retrying (Retry(total=4, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x00000000046D4DA0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',)': /simple/mglearn/\n",
      "  Retrying (Retry(total=3, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x00000000046D4FD0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',)': /simple/mglearn/\n",
      "  Retrying (Retry(total=2, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x00000000046D4A90>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',)': /simple/mglearn/\n",
      "  Retrying (Retry(total=1, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x00000000046D4EF0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',)': /simple/mglearn/\n",
      "  Retrying (Retry(total=0, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x00000000046D45F8>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',)': /simple/mglearn/\n",
      "  Could not find a version that satisfies the requirement mglearn (from versions: )\n",
      "No matching distribution found for mglearn\n"
     ]
    }
   ],
   "source": [
    "!pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-149fcfcb6c4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'svc' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, threshold = precision_recall_curve(y_test, svc.decision_function(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_features must be in (0, n_features]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-1b04a6c825ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# RandomForestClassifier has predict_proba, but not decison_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 326\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_depth must be greater than zero. \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_features must be in (0, n_features]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
      "\u001b[1;31mValueError\u001b[0m: max_features must be in (0, n_features]"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 0, max_features = 100)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# RandomForestClassifier has predict_proba, but not decison_function\n",
    "precision_rf, recall_rf, threshold_rf = precision_recall_curve(y_test, rf.predict_proba(x_test[:,1]))\n",
    "plt.plot(precision, recall,label = 'svc')\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o',markersize = 10, label = 'threshold zero svc', fillstyle = 'none',\n",
    "        c = 'k', mew = 2)\n",
    "plt.plot(precision_rf, recall_rf, label = 'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
