{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "csv_data = \"\"\"A, B,C D,\n",
    "1.0,2.0,3.0,4.0,\n",
    "5.0,6.0,0.7,8.0,\n",
    "9.0,0.0,11.0,12.0\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A     B   C D  Unnamed: 3\n",
      "1.0  2.0   3.0   4.0         NaN\n",
      "5.0  6.0   0.7   8.0         NaN\n",
      "9.0  0.0  11.0  12.0         NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(StringIO(csv_data))\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A             0\n",
       " B            0\n",
       "C D           0\n",
       "Unnamed: 3    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the isnull method to return a dataframe with boolean values\n",
    "# that indicate wheater a cell contains a numeric value (false) or if\n",
    "# data is missing(True), using the sum method, we can then return the number\n",
    "# of missing values per column as follows.\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', ' B', 'C D', 'Unnamed: 3'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Unnamed: 3'] = [3.0,4.0,6.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C D</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B   C D  Unnamed: 3\n",
       "1.0  2.0   3.0   4.0         3.0\n",
       "5.0  6.0   0.7   8.0         4.0\n",
       "9.0  0.0  11.0  12.0         6.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.indexing._LocIndexer object at 0x0000000008E102B0>\n"
     ]
    }
   ],
   "source": [
    "print (df.loc(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C D</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B   C D  Unnamed: 3\n",
       "1.0  2.0   3.0   4.0         3.0\n",
       "5.0  6.0   0.7   8.0         4.0\n",
       "9.0  0.0  11.0  12.0         6.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminating samples or features with missing values\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C D</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B   C D  Unnamed: 3\n",
       "1.0  2.0   3.0   4.0         3.0\n",
       "5.0  6.0   0.7   8.0         4.0\n",
       "9.0  0.0  11.0  12.0         6.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarly we can drop columns that have at least one NaN in any row by setting\n",
    "# the axis argument to 1\n",
    "df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C D</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B   C D  Unnamed: 3\n",
       "1.0  2.0   3.0   4.0         3.0\n",
       "5.0  6.0   0.7   8.0         4.0\n",
       "9.0  0.0  11.0  12.0         6.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to drop rows when all columns are NaN\n",
    "df.dropna(how = 'all')\n",
    "\n",
    "# drop row that have not at least 4 non-NaN values\n",
    "df.dropna(thresh = 4)\n",
    "\n",
    "# only drop rows where NaN appear in specific columns (here:'c')\n",
    "#df.dropna(subset = ['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.    3.    4.    3. ]\n",
      " [  6.    0.7   8.    4. ]\n",
      " [  0.   11.   12.    6. ]]\n"
     ]
    }
   ],
   "source": [
    "# imputing missing values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imr = imr.fit(df)\n",
    "imputed_data = imr.transform(df.values)\n",
    "print (imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the fit method is used to learn parameters from the training data, and\n",
    "# the transform method uses those parameters to transform the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handling categorical variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Categorical variable can further be distinguished between norminal and ordinal features.\n",
    "\n",
    "ordinal features can be understood as categorical values that can be sorted or ordered.\n",
    "\n",
    "norminal features don't imply any order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    ['green', 'M', 10.0, 'class1'],\n",
    "    ['red', 'L', 13.5, 'class2'],\n",
    "    ['blue', 'XL', 15.3, 'class1']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color size  price classlabel\n",
      "0  green    M   10.0     class1\n",
      "1    red    L   13.5     class2\n",
      "2   blue   XL   15.3     class1\n"
     ]
    }
   ],
   "source": [
    "df.columns = ['color', 'size', 'price', 'classlabel']\n",
    "\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The above dataframe contains a nominal feature (color), an ordinal feature (size), and a numerical feature (price) column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # mapping ordinal features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To make sure that the learning algorithm interprets the ordinal features correctly, we need to convert the categorical string values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_mapping = {'XL':3, 'L':2,'M':1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['size'] = df['size'].map(size_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green     1   10.0     class1\n",
       "1    red     2   13.5     class2\n",
       "2   blue     3   15.3     class1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we want to transform the interger values back to the original string representation at a later stage, we can simply define a reverse-mapping dictionary inv_size_mapping = {v:k for k, v in size_mapping.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class_mapping = {label:idx for idx, label in enumerate(np.unique(df['classlabel']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class1': 0, 'class2': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['classlabel'] = df['classlabel'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price  classlabel\n",
       "0  green     1   10.0           0\n",
       "1    red     2   13.5           1\n",
       "2   blue     3   15.3           0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " we can reverse the key-value pairs in the mapping dictionary as follows to map the converted class labels back to the original string representation\n",
    " inv_class_mapping = {v:k for k , v in class_mapping.items()}\n",
    " df['classlabel'] = df['classlabel'].map(inv_class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('class1', 0), ('class2', 1)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('XL', 3), ('L', 2), ('M', 1)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_mapping.items()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Alternatively, there is a convenient LabelEncoder class directly implemented in scikit-learn to achieve the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(df['classlabel'].values)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "note that the fit_transform methos is just a shortcut for calling fit and transform separately, and we can use the inverse_transform method to transform the integer class labels back into their original string representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price  classlabel\n",
       "0  green     1   10.0           0\n",
       "1    red     2   13.5           1\n",
       "2   blue     3   15.3           0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performing one-hot encoding on nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 10.0]\n",
      " [2 2 13.5]\n",
      " [0 3 15.3]]\n"
     ]
    }
   ],
   "source": [
    "x = df[['color', 'size', 'price']].values\n",
    "color_le = LabelEncoder()\n",
    "x[:, 0] = color_le.fit_transform(x[:,0])\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "With this the learning algorithm will now assume that green is larger than blue, and red is larger than green. Although this assumption is incorrect, the algorithm could still produce useful results. However, those results would not be optimal.\n",
    "\n",
    "A common workaround for this problem is to use a technique called one-hot encoding. The idea behind this approach is to create a new dummy feature for each unique value in the nominal feature column. \n",
    "\n",
    "Here we will convert the color feature into three new features: blue, green and red. Binary values can then be used to indicate the particular color of a sample; for example a blue sample can be encoded as blue = 1, green = 0, red = 0.\n",
    "\n",
    "To perfrom this transformation we can use the onehot encoder that is implemented in the scikit-learn.preprocessing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0. ,   1. ,   0. ,   1. ,  10. ],\n",
       "       [  0. ,   0. ,   1. ,   2. ,  13.5],\n",
       "       [  1. ,   0. ,   0. ,   3. ,  15.3]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categorical_features = [0])\n",
    "ohe.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the get_dummies method implemented in pandas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "the get_dummies method will only convert string columns and leave all other columns unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  size  color_blue  color_green  color_red\n",
       "0   10.0     1           0            1          0\n",
       "1   13.5     2           0            0          1\n",
       "2   15.3     3           1            0          0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df[['price', 'color', 'size']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "x,y = iris.data, iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing features onto the same scale"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are two common approaches to bringing different features onto the same scale; normalization and standardization.\n",
    "\n",
    "normalization refers to rescaling of the features to a range of [0,1], which is a special case of min-max scaling.\n",
    "\n",
    "Using standardization, we center the feature columns at mean 0 with standard deviation 1 so that the feature columns take the form of a normal distribution, which makes it easier to learn the weights. Furthermore, standardization maintains useful infromation about outliers and makes the algorithm less sensitive to them in contrast to min-max scaling, which scales the data to a limited range of values.\n",
    "standardization can be more practical for many machine learning algorithms.\n",
    "\n",
    "\n",
    "The min-max scaling procedure is implemented in scikit-learn and can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "x_train_norm = mms.fit_transform(x_train)\n",
    "x_test_norm = mms.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# similar to MinMaxScaler, scikit-learn also implements a class for\n",
    "# standardization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "x_train_std = stdsc.fit_transform(x_train)\n",
    "x_test_std = stdsc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selecting meaniful features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if we notice that a model performs much better on training dataset than on the test dataset, this observation is a strong indicator for overfitting. Overfitting means that model fits the parameter too closely to the particular observations in the training dataset but does not generalize well to real data-- we say that the model has a high variance.\n",
    "\n",
    "common solution to reduce the generalization error are:\n",
    "1. collect more training data.\n",
    "2. introduce a penalty for complexity via regularization\n",
    "3. Choose a simpler model with fewer parameters.\n",
    "4. Reduce the dimensionality of the data.\n",
    "\n",
    "\n",
    "To reduce overfitting we employ regularization and dimensionality reduction via feature selection."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "L1 regularization yields sparse feature vectors; most feature weight will be zero. Sparsity can be useful in practice if we have a high-dimensional dataset with many features that are irrelvant, especially cases where we have more irrelevant dimension than samples. In this sense, L1 regularization can be understood as a technique for feature selection.\n",
    "\n",
    "our goal is to minimize the sum of the unpenalized cost function plus the penalty term, which can be understood as adding bias and preferring a simpler model to reduce the variance in the absence of sufficient training data to fit the model.\n",
    "\n",
    "for regurlarized models in scikit-learn that support L1 regularization, we can simply set the penalty parameter to l1 to yield the sparse solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression(penalty = 'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty = 'l1', C = 0.1)\n",
    "lr.fit(x_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.819047619048\n",
      "Test accuracy:  0.711111111111\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \", lr.score(x_train_std, y_train))\n",
    "print(\"Test accuracy: \", lr.score(x_test_std, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "this doesn't indicate overfitting\n",
    "when we access the intercept term via the lr.intercept_ attribute\n",
    "since we fit the LogisticRegression object on a multiclass dataset, it uses One-vs-Rest(OvR) approach by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.40054185, -0.42762577, -0.24901363])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.21720825, -1.76363189,  0.        ],\n",
       "       [ 0.        , -0.46520901,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.50473536]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularization path plot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "finally, plotting the regularization path, which is the weight coefficients of the different features for different regularization strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:545: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEOCAYAAACXX1DeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc454908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "colors = ['blue', 'green', 'red','cyan','magenta','yellow','black',\n",
    "         'pink','lightgreen','lightblue','gray','indigo','orange']\n",
    "weights, params = [],[]\n",
    "for c in np.arange(-4,6):\n",
    "    lr = LogisticRegression(penalty = 'l1',C = pow(10,np.abs(c)), random_state = 0)\n",
    "    lr.fit(x_train_std, y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**np.abs(c))\n",
    "weights = np.array(weights)\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:,column], color = color)\n",
    "\n",
    "plt.axhline(0, color = 'black', linestyle = '--', linewidth = 3)\n",
    "plt.xlim(10**(-5), 10**5)\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc = 'upper left')\n",
    "ax.legend(loc = 'upper center', bbox_to_anchor = (1,38,1.03), ncols = 1, fancybox = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sequential feature selection algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "An alternatve way to reduce the complexity of the model and avoid overfitting is dimensionality reduction via feature selection which is especially useful for unregularized models. There are two main categories of diemesionality reduction techniques: feature selection and feature extraction. Using feature selection, we select a subset of the orignal features. In feature, extraction, we derive information from the feature set to construct a new feature subspace.\n",
    "\n",
    "\n",
    "The motivation behind feature selection algorithms is to automatically select a subset of features that are most relevant to the problem to removing irrelevant features or noise, which can be useful for algorithms that don't support regularization. A classic sequential feature selection algorithm is SEQUENTIAL BACKWARD SELECTION (SBS), which aims to reduce the dimensionality of the inital feature subspace with a minimal decay in perfromance of the classifier to improve upon computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unfortunately, the SBS algorithm is not implemeted in scikit-learn\n",
    "# implementing this in python from scratch we have.\n",
    "\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, scoring = accuracy_score,\n",
    "                 test_size = 0.25, random_state = 1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = self.test_size,\n",
    "                                                           random_state = self.random_state)\n",
    "        dim = x_train.shape[1]\n",
    "        self.indice = tuple(range(dim))\n",
    "        self.subsets = [self.indices_]\n",
    "        score = self.calc_score(x_train, y_train,x_test,y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "        \n",
    "        while dim > self.k_features:\n",
    "            score = []\n",
    "            subsets = []\n",
    "            \n",
    "            for p in combinations(self.indices_, r = dim-1):\n",
    "                score = self._calc_score(x_train, y_train, x_test,y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "                \n",
    "            best = np.argmax(scores)\n",
    "            self.indices = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "            \n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score = self.scores_[-1]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transfrom(self, x):\n",
    "        return x[:, self.indices_]\n",
    "    \n",
    "    \n",
    "    def _cal_score(self, x_train, y_train, x_test, y_test, indices):\n",
    "        self.estimator.fit(x_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(x_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SBS' object has no attribute 'indices_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-776a6af020ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSBS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_features\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-76-7e3e406d0de5>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SBS' object has no attribute 'indices_'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "knn = KNeighborsClassifier(n_neighbors = 2)\n",
    "sbs = SBS(knn, k_features= 1)\n",
    "sbs.fit(x_train_std,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing feature importance with random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-8ef27f82acf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"%2d) %-*s %f\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeat_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels = iris.data\n",
    "forest = RandomForestClassifier(n_estimators = 10000, random_state = 0, n_jobs = -1)\n",
    "forest.fit(x_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(x_train.shape[1]):\n",
    "    print (\"%2d) %-*s %f\" %(f+1,30,feat_labels(f), importances(indices[f])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(x_train.shape[1], importances[indices], color = 'lightblue',align = 'center'))\n",
    "plt.xticks(range(x_train.shape[1], feat_labels, rotation = 90))\n",
    "plt.xlim(-1,x_train.shape[1])\n",
    "plt.tight_layout()\n",
    "plt.show(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
